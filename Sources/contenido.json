{"contenido":[
    {"tag":"saludo",
        "patrones":["hola","un saludo","hello"],
        "respuestas":["Hola que tal!","Como te va?","Un gusto de verte"]
    },
    {"tag":"despedida",
        "patrones":["adios","nos vemos","hasta la proxima"],
        "respuestas": ["cuidate","adios","nos vemos pronto"]
    },
    {"tag":"python",
        "patrones":["que es Python?","Lenguaje de programacion Python", "Ayuda Python"],
        "respuestas": ["Python es un lenguaje de programacion no tipado utilizado para muchas aplicaciones profesionales  \r\n  desde videojuegos hasta Machine Learning; Para mas informacion sobre Python deberias dirigirte a: https://www.python.org/"]
    },
    {
        "tag": "stdout",
        "patrones": ["Setting the correct encoding when piping stdout in Python"],
        "respuestas": ["First, regarding this solution: It's not practical to explicitly print with a given encoding every time. That would be repetitive and error-prone.  A better solution is to change sys.stdout at the start of your program, to encode with a selected encoding. Here is one solution I found on  href=\"\"http://drj11.wordpress.com/2007/05/14/python-how-is-sysstdoutencoding-chosen/\"\">Python: How is sys.stdout.encoding chosen?</, in particular a comment by \"\"toka\"\":  import sys import codecs sys.stdout = codecs.getwriter('utf8')(sys.stdout) </pre> "]
    },
    {
        "tag": "virtualenv",
        "patrones": ["How do you use pip, virtualenv and Fabric to handle deployment?" , "How do I update pip itself from inside my virtual environment?"],
        "respuestas": ["\"\"Best practices\"\" are very context-dependent, so I won't claim my practices are best, just that they work for me. I work on mostly small sites, so no multiple-server deployments, CDNs etc. I do need to support Webfaction shared hosting deployment, as some clients need the cheapest hosting they can find. I do often have to deploy sites multiple times in different environments, so repeatable scripted deploys are critical.  <ul> I don't use pip bundles, I install from a requirements.txt. I do run my own  href=\"\"http://github.com/ask/chishop\"\" rel=\"\"nofollow\"\">chishop</ server with sdists of everything I need, so there aren't multiple single points of failure in the build process. I also use PIP_DOWNLOAD_CACHE on my development machines to speed up bootstrapping project environments, since most of my projects' requirements overlap quite a bit.</li> I have  href=\"\"http://fabfile.org\"\" rel=\"\"nofollow\"\">Fabric</ scripts that can automatically set up and configure nginx + Apache/mod_wsgi on an Ubuntu VPS, or configure the equivalent on  href=\"\"http://webfaction.com\"\" rel=\"\"nofollow\"\">Webfaction</ shared hosting, and then deploy the project.</li> I do not use --no-site-packages with virtualenv, because I prefer having slow-moving compiled packages (Python Imaging Library, psycopg2) installed at the system level; too slow and troublesome to do inside every virtualenv. I have not had trouble with polluted system site-packages, because I generally don't pollute it. And in any case, you can install a different version of something in the virtualenv and it will take precedence.</li> Each project has its own virtualenv. I have some bash scripts (not  href=\"\"http://www.doughellmann.com/projects/virtualenvwrapper/\"\" rel=\"\"nofollow\"\">virtualenvwrapper</, though a lot of people use that and love it) that automate deploying the virtualenv for a given project to a known location and installing that project's requirements into it.</li> The entire deployment process, from a bare Ubuntu server VPS or Webfaction shared hosting account to a running website, is scripted using Fabric.</li> Fabric scripts are part of the project source tree, and I run them from a local development checkout.</li> I have no need for SCons (that I am aware of).</li> </ul>  <h2>Deployment</h2>  At the moment a fresh deployment is split into these steps:  <ul> fab staging bootstrap (server setup and initial code deploy)</li> fab staging enable (enable the Apache/nginx config for this site)</li> fab staging reload_server (reload Apache/nginx config).</li> </ul>  Those can of course be combined into a single command line fab staging bootstrap enable reload_server.  Once these steps are done, updating the deployment with new code is just fab staging deploy.  If I need to roll back an update, fab staging rollback. Nothing particularly magical in the rollback; it just rolls back the code to the last-deployed version and migrates the database to the previous state (this does require recording some metadata about the migration state of the DB post-deploy, I just do that in a text file).  <h2>Examples</h2>  I haven't used the Fabric scripts described in this answer for a few years, so they aren't maintained at all and I disclaim responsibility for their quality :-) But you can see them at  href=\"\"https://bitbucket.org/carljm/django-project-template\"\" rel=\"\"nofollow\"\">https://bitbucket.org/carljm/django-project-template</ - in fabfile.py in the repo root, and in the deploy/ subdirectory. ],[pip is just a  href=\"\"https://pypi.python.org/pypi/pip\"\">PyPI package</ like any other; you could use it to upgrade itself the same way you would upgrade any package:  pip install --upgrade pip </pre>  On Windows the  href=\"\"https://pip.pypa.io/en/stable/installing/#upgrading-pip\"\">recommended command</ is:  python -m pip install --upgrade pip </pre> "]
    },
    {
        "tag": "buildout",
        "patrones": ["The problem with installing PIL using virtualenv or buildout"],
        "respuestas": ["The PIL version packaged on pypi (by the author) is incompatible with setuptools and thus not easy_installable. People have created easy_installable versions elsewhere. Currently, you need to specify a find-links URL and use  href=\"\"https://pypi.python.org/pypi/pip\"\">pip</ get a good package:  pip install --no-index -f http://dist.plone.org/thirdparty/ -U PIL </pre>  By using pip install with the --no-index you avoid running the risk of finding the PyPI (non-fixed) original of PIL. If you were to use easy_install, you must use a direct link to the source tarball of a corrected version; easy_install stubbornly still uses the PyPI link over the find-links URL:  easy_install http://dist.plone.org/thirdparty/PIL-1.1.7.tar.gz </pre>  To include PIL in a buildout, either specify the egg with the same version pin or use a versions section:  [buildout] parts = find-links =     http://dist.plone.org/thirdparty/ eggs =     PIL versions = versions  [versions] PIL = 1.1.7 </pre>  Edit March 2011: Fixes to address the packaging issues have been merged into  href=\"\"http://hg.effbot.org/pil-2009-raclette/overview\"\">PIL's development tree</ now, so this workaround may soon be obsolete.  Edit February 2013: Just use  href=\"\"http://stackoverflow.com/a/7770547\"\">Pillow</ and be done with it. :-) Clearly waiting for the original package to be fixed has not paid off. "]
    },
    {
        "tag": "mingw",
        "patrones": ["How to use MinGW's gcc compiler when installing Python package using Pip?"],
        "respuestas": ["<ul> install MinGW with C++ Compiler option checked</li> add C:\\MinGW\\bin to your PATH</li> in PYTHONPATH\\Lib\\distutils, create a file distutils.cfg and add these lines:</li> </ul>   [build] compiler=mingw32  "]
    },
    {
        "tag": "subprocess",
        "patrones": ["How do I pipe a subprocess call in Python to a text file?"],
        "respuestas": ["If you want to write the output to a file you can use the  href=\"\"http://docs.python.org/library/subprocess.html#subprocess.Popen\"\">stdout</-argument of subprocess.call.  It takes None, subprocess.PIPE, a file object or a file descriptor. The first is the default, stdout is inherited from the parent (your script). The second allows you to pipe from one command/process to another. The third and fourth are what you want, to have the output written to a file.  You need to open a file with something like open and pass the object or file descriptor integer to call:  f = open(\"\"blah.txt\"\", \"\"w\"\") subprocess.call([\"\"/home/myuser/run.sh\"\", \"\"/tmp/ad_xml\"\",  \"\"/tmp/video_xml\"\"], stdout=f) </pre>  I'm guessing any valid file-like object would work, like a socket (gasp :)), but I've never tried.  As  href=\"\"http://stackoverflow.com/users/89806/marcog\"\">marcog</ mentions in the comments you might want to redirect stderr as well, you can redirect this to the same location as stdout with stderr=subprocess.STDOUT. Any of the above mentioned values works as well, you can redirect to different places. "]
    },
    {
        "tag": "google-app-engine",
        "patrones": ["How do I manage third-party Python libraries with Google App Engine? (virtualenv? pip?)"],
        "respuestas": ["Here's how I do it:  <ul> project <ul> .Python</li> bin</li> lib <ul> python2.5  <ul> site-packages <ul> &lt; pip install packages here ></li> </ul></li> </ul></li> </ul></li> include</li> src <ul> app.yaml </li> index.yaml</li> main.yaml</li> &lt; symlink the pip installed packages in ../lib/python2.5/site-packages </li> </ul></li> </ul></li> </ul>  The project directory is the top level directory where the virtualenv sits. I get the virtualenv using the following commands:  cd project virtualenv -p /usr/bin/python2.5 --no-site-packages --distribute . </pre>  The src directory is where all your code goes. When you deploy your code to GAE, *<em>only</em>* deploy those in the src directory and nothing else. The appcfg.py will resolve the symlinks and copy the library files to GAE for you.  I don't install my libraries as zip files mainly for convenience in case I need to read the source code, which I happen to do a lot just out of curiosity. However, if you really want to zip the libraries, put the following code snippet into your main.py  import sys for p in ['librarie.zip', 'package.egg'...]:     sys.path.insert(0, p) </pre>  After this you can import your zipped up packages as usual.  One thing to watch out for is setuptools' pkg_resources.py. I copied that directly into my src directory so my other symlinked packages can use it. Watch out for anything that uses entry_points. In my case I'm using Toscawidgets2 and I had to dig into the source code to manually wire up the pieces. It can become annoying if you had a lot of libraries that rely on entry_point. "]
    },
    {
        "tag": "mysql",
        "patrones": ["Installing specific package versions with pip (MY SQL)"],
        "respuestas": ["First, I see two issues with what you're trying to do. Since you already have an installed version, you should either uninstall the current existing driver or use pip install -I MySQL_python==1.2.2  However, you'll soon find out that this doesn't work. If you look at pip's installation log, or if you do a pip install -Iv MySQL_python==1.2.2 you'll find that the PyPI URL link does not work for MySQL_python v1.2.2. You can verify this here:  href=\"\"http://pypi.python.org/pypi/MySQL-python/1.2.2\"\">http://pypi.python.org/pypi/MySQL-python/1.2.2</  The download link 404s and the fallback URL links are re-directing infinitely due to sourceforge.net's recent upgrade and PyPI's stale URL.  So to properly install the driver, you can follow these steps:  pip uninstall MySQL_python pip install -Iv http://sourceforge.net/projects/mysql-python/files/mysql-python/1.2.2/MySQL-python-1.2.2.tar.gz/download </pre> "]
    },
    {
        "tag": "setuptools",
        "patrones": ["What is the official setuptools way to install pip and virtualenv systemwide?"],
        "respuestas": ["If you can install the latest Python (2.7.9 and up) Pip is now bundled with it.  See:  href=\"\"https://docs.python.org/2.7//installing/index.html\"\">https://docs.python.org/2.7//installing/index.html</<br> If not :<br> Update (from the release notes):  <blockquote>   Beginning with v1.5.1, pip does not require setuptools prior to running get-pip.py. Additionally, if setuptools (or distribute) is not already installed, get-pip.py will install setuptools for you. </blockquote>  I now run the regular:  curl --silent --show-error --retry 5 https://bootstrap.pypa.io/get-pip.py | sudo python2.7 </pre>  Here are the official installation instructions:  href=\"\"http://pip.readthedocs.org/en/latest/installing.html#install-pip\"\">http://pip.readthedocs.org/en/latest/installing.html#install-pip</  EDIT 25-Jul-2013:<br> Changed URL for setuptools install.    EDIT 10-Feb-2014:<br> Removed setuptools install (thanks @Ciantic)  EDIT 26-Jun-2014:<br> Updated URL again (thanks @LarsH)  EDIT 1-Mar-2015:<br> Pip is now bundled with Python  "]
    },
    {
        "tag": "pycrypto",
        "patrones": ["Broken Pipe error when using pip to install pycrypto on Mac OS X"],
        "respuestas": ["If you have installed Xcode 4, try setting ARCHFLAGS before calling pip or easy_install:  sudo bash export ARCHFLAGS='-arch i386 -arch x86_64' pip ... </pre>  The problem is that Xcode 4 has removed support for -arch ppc but the system Python 2.6 on Mac OS X 10.6 expects to build universal C extension modules with all three architectures.  And if you define the environment variable prior to the sudo command, it will likely not be exported through to the sudo environment. "]
    },
    {
        "tag": "pip",
        "patrones": ["Python - manually install package using virtualenv"],
        "respuestas": ["I typically would extract the program to a temporary folder, then from that folder, run the setup.py using the direct path to the virtualenv python instance.  eg if your virtualenv is in /home/username/virtualpy, use this (from your temporary folder)  /home/username/virtualpy/bin/python setup.py install </pre>  This should install it to your virtualenv site package folder. "]
    },
    {
        "tag": "python 3",
        "patrones": ["How to install pip with Python 3?"],
        "respuestas": ["I was able to install pip for python 3 on Ubuntu just by running sudo apt-get install python3-pip.  "]
    },
    {
        "tag": "pkg_resources",
        "patrones": ["No module named pkg_resources"],
        "respuestas": ["I encountered the same ImportError today while trying to use pip. Somehow the setuptools package had been deleted in my Python environment.  To fix the issue, run the setup script for setuptools:  wget https://bootstrap.pypa.io/ez_setup.py -O - | python </pre>  (or if you don't have wget installed (e.g. OS X), try  curl https://bootstrap.pypa.io/ez_setup.py | python </pre>  possibly with sudo prepended.)  If you have any version of  href=\"\"http://pythonhosted.org/setuptools/merge-faq.html\"\">distribute</, or any setuptools below 0.6, you will have to uninstall it first.*  See  href=\"\"https://pypi.python.org/pypi/setuptools/0.9.8#installation-instructions\"\">Installation Instructions</ for further details.  <hr>  * If you already have a working distribute, upgrading it to the \"\"compatibility wrapper\"\" that switches you over to setuptools is easier. But if things are already broken, don't try that. "]
    },
    {
        "tag": "multiprocessing",
        "patrones": ["Python multiprocessing - Pipe vs Queue"],
        "respuestas": ["<ul> A  href=\"\"http://docs.python.org/library/multiprocessing.html#multiprocessing.Pipe\"\">Pipe()</ can only have two endpoints.</li> A  href=\"\"http://docs.python.org/library/multiprocessing.html#multiprocessing.Queue\"\">Queue()</ can have multiple producers and consumers.</li> </ul>  When to use them  If you need more than two points to communicate, use a  href=\"\"http://docs.python.org/library/multiprocessing.html#multiprocessing.Queue\"\">Queue()</.  If you need absolute performance, a  href=\"\"http://docs.python.org/library/multiprocessing.html#multiprocessing.Pipe\"\">Pipe()</ is much faster because Queue() is built on top of Pipe().  Performance Benchmarking  Let's assume you want to spawn two processes and send messages between them as quickly as possible.  These are the timing results of a drag race between similar tests using Pipe() and Queue()... This is on a ThinkpadT61 running Ubuntu 11.10, and Python 2.7.2.  FYI, I threw in results for  href=\"\"http://docs.python.org/library/multiprocessing.html#multiprocessing.JoinableQueue\"\">JoinableQueue()</ as a bonus; JoinableQueue() accounts for tasks when queue.task_done() is called (it doesn't even know about the specific task, it just counts unfinished tasks in the queue), so that queue.join() knows the work is finished.  The code for each at bottom of this answer...  mpenning@mpenning-T61:~$ python multi_pipe.py  Sending 10000 numbers to Pipe() took 0.0369849205017 seconds Sending 100000 numbers to Pipe() took 0.328398942947 seconds Sending 1000000 numbers to Pipe() took 3.17266988754 seconds mpenning@mpenning-T61:~$ python multi_queue.py  Sending 10000 numbers to Queue() took 0.105256080627 seconds Sending 100000 numbers to Queue() took 0.980564117432 seconds Sending 1000000 numbers to Queue() took 10.1611330509 seconds mpnening@mpenning-T61:~$ python multi_joinablequeue.py  Sending 10000 numbers to JoinableQueue() took 0.172781944275 seconds Sending 100000 numbers to JoinableQueue() took 1.5714070797 seconds Sending 1000000 numbers to JoinableQueue() took 15.8527247906 seconds mpenning@mpenning-T61:~$ </pre>  In summary Pipe() is about three times faster than a Queue().  Don't even think about the JoinableQueue() unless you really must have the benefits.  BONUS MATERIAL 2  Multiprocessing introduces subtle changes in information flow that make debugging hard unless you know some shortcuts.  For instance, you might have a script that works fine when indexing through a dictionary in under many conditions, but infrequently fails with certain inputs.  Normally we get clues to the failure when the entire python process crashes; however, you don't get unsolicited crash tracebacks printed to the console if the multiprocessing function crashes.  Tracking down unknown multiprocessing crashes is hard without a clue to what crashed the process.  The simplest way I have found to track down multiprocessing crash informaiton is to wrap the entire multiprocessing function in a try / except and use traceback.print_exc():  import traceback def reader(args):     try:         # Insert stuff to be multiprocessed here         return args[0]['that']     except:         print \"\"FATAL: reader({0}) exited while multiprocessing\"\".format(args)          traceback.print_exc() </pre>  Now, when you find a crash you see something like:  FATAL: reader([{'crash', 'this'}]) exited while multiprocessing Traceback (most recent call last):   File \"\"foo.py\"\", line 19, in __init__     self.run(task_q, result_q)   File \"\"foo.py\"\", line 46, in run     raise ValueError ValueError </pre>  Source Code:  <hr>  \"\"\"\"\"\" multi_pipe.py \"\"\"\"\"\" from multiprocessing import Process, Pipe import time  def reader(pipe):     output_p, input_p = pipe     input_p.close()    # We are only reading     while True:         try:             msg = output_p.recv()    # Read from the output pipe and do nothing         except EOFError:             break  def writer(count, input_p):     for ii in xrange(0, count):         input_p.send(ii)             # Write 'count' numbers into the input pipe  if __name__=='__main__':     for count in [10**4, 10**5, 10**6]:         output_p, input_p = Pipe()         reader_p = Process(target=reader, args=((output_p, input_p),))         reader_p.start()     # Launch the reader process          output_p.close()       # We no longer need this part of the Pipe()         _start = time.time()         writer(count, input_p) # Send a lot of stuff to reader()         input_p.close()        # Ask the reader to stop when it reads EOF         reader_p.join()         print \"\"Sending %s numbers to Pipe() took %s seconds\"\" % (count,              (time.time() - _start)) </pre>  <hr>  \"\"\"\"\"\" multi_queue.py \"\"\"\"\"\" from multiprocessing import Process, Queue import time  def reader(queue):     while True:         msg = queue.get()         # Read from the queue and do nothing         if (msg == 'DONE'):             break  def writer(count, queue):     for ii in xrange(0, count):         queue.put(ii)             # Write 'count' numbers into the queue     queue.put('DONE')  if __name__=='__main__':     for count in [10**4, 10**5, 10**6]:         queue = Queue()   # reader() reads from queue                           # writer() writes to queue         reader_p = Process(target=reader, args=((queue),))         reader_p.daemon = True         reader_p.start()     # Launch the reader process          _start = time.time()         writer(count, queue)    # Send a lot of stuff to reader()         reader_p.join()         # Wait for the reader to finish         print \"\"Sending %s numbers to Queue() took %s seconds\"\" % (count,              (time.time() - _start)) </pre>  <hr>  \"\"\"\"\"\" multi_joinablequeue.py \"\"\"\"\"\" from multiprocessing import Process, JoinableQueue import time  def reader(queue):     while True:         msg = queue.get()         # Read from the queue and do nothing         queue.task_done()  def writer(count, queue):     for ii in xrange(0, count):         queue.put(ii)             # Write 'count' numbers into the queue  if __name__=='__main__':     for count in [10**4, 10**5, 10**6]:         queue = JoinableQueue()   # reader() reads from queue                                   # writer() writes to queue         reader_p = Process(target=reader, args=((queue),))         reader_p.daemon = True         reader_p.start()     # Launch the reader process          _start = time.time()         writer(count, queue) # Send a lot of stuff to reader()         queue.join()         # Wait for the reader to finish         print \"\"Sending %s numbers to JoinableQueue() took %s seconds\"\" % (count,              (time.time() - _start)) </pre> "]
    },
    {
        "tag": "ruby",
        "patrones": ["What are the Python equivalents to Ruby's bundler / Perl's carton?"],
        "respuestas": ["From what i've read about bundler — pip without virtualenv should work just fine for you. You can think of it as something between regular gem command and bundler. Common things that you can do with pip:   Installing packages (gem install)  pip install mypackage </pre></li> Dependencies and bulk-install (gemfile)  Probably the easiest way is to use pip's requirements.txt files. Basically it's just a plain list of required packages with possible version constraints. It might look something like:  nose==1.1.2 django&lt;1.3 PIL </pre>  Later when you'd want to install those dependencies you would do:  $ pip install -r requirements.txt </pre>  A simple way to see all your current packages in requirements-file syntax is to do:  $ pip freeze </pre>  You can read more about it  href=\"\"http://pip.readthedocs.org/en/latest/user_guide.html#requirements-files\"\">here</.</li> Execution (bundler exec)  All python packages that come with executable files are usually directly available after install (unless you have custom setup or it's a special package). For example:  $ pip install gunicorn $ gunicorn -h  </pre></li> Package gems for install from cache (bundler package)  There is pip bundle and pip zip/unzip. But i'm not sure if many people use it.</li> </ol>  p.s. If you do care about environment isolation you can also use virtualenv together with pip (they are close friends and work perfectly together). By default pip installs packages system-wide which might require admin rights.  "]
    },
    {
        "tag": "ubuntu",
        "patrones": ["How to install python3 version of package via pip on Ubuntu?","trying to install pymssql on ubuntu 12.04 using pip","ubuntu"],
        "respuestas": ["Ubuntu 12.10+ and Fedora 13+ have a package called python3-pip which will install pip-3.2 (or pip-3.3, pip-3.4 or pip3 for newer versions) without needing this jumping through hoops.  <hr>  I came across this and fixed this without needing the likes of wget or virtualenvs (assuming Ubuntu 12.04):   Install package python3-setuptools: run sudo aptitude install python3-setuptools, this will give you the command easy_install3.</li> Install pip using Python 3's setuptools: run sudo easy_install3 pip, this will give you the command pip-3.2 like kev's solution.</li> Install your PyPI packages: run sudo pip-3.2 install &lt;package&gt; (installing python packages into your base system requires root, of course).</li> …</li> Profit!</li> </ol> ],[You need to install the FreeTDS development package (freetds-dev) before trying to install pymssql with pip:  $ sudo apt-get install freetds-dev </pre>  and then, in your <em>virtualenv</em> or wherever you wish to install it:  $ pip install pymssql </pre> "]
    },
    {
        "tag": "easy-install",
        "patrones": ["Python Packages Offline Installation"],
        "respuestas": ["I use the -d (or --download) option to pip install, which makes the process of downloading sdist tarballs from PyPI much simpler. For instance, pip install --download /path/to/some/dir celery will download the sdist tarballs for celery and all its dependencies to /path/to/some/dir (but will not install them). Then you can use pip install --no-index --find-links /path/to/some/dir/ celery to install celery using those downloaded sdists, without accessing the network.  The same process works if you replace celery in both commands with -r requirements.txt, where requirements.txt is a pip requirements file listing all the packages you want (and optionally the versions you want).  UPDATE  <blockquote>   DEPRECATION: pip install --download has been deprecated and will be   removed in the future. Pip now has a download command that should be   used instead. </blockquote> "]
    },
    {
        "tag": "numpy",
        "patrones": ["Installing SciPy and NumPy using pip"],
        "respuestas": ["This worked for me on Ubuntu 14.04:  sudo apt-get install libblas-dev liblapack-dev libatlas-base-dev gfortran pip install scipy </pre> "]
    },
    {
        "tag": "yaml",
        "patrones": ["How do I install the yaml package for Python?", "yaml"],
        "respuestas": ["You could try the search feature in pip,   $ pip search yaml </pre>  which looks for packages in PyPI with yaml in the short description.  That reveals various packages, including PyYaml, yamltools, and PySyck, among others (Note that  href=\"\"http://pyyaml.org/wiki/PySyck\"\">PySyck docs</ recommend using PyYaml, since syck is out of date).  Now you know a specific package name, you can install it:  $ pip install pyyaml </pre>  If you want to install python yaml system-wide in linux, you can also use a package manager, like aptitude or yum:  $ sudo apt-get install python-yaml $ sudo yum install python-yaml </pre> "]
    },
    {
        "tag": "anaconda",
        "patrones": ["How do I keep track of pip-installed packages in an Anaconda (Conda) environment?","anaconda"],
        "respuestas": ["conda will only keep track of the packages it installed. And pip will give you the packages that were either installed using the pip installer itself or they used setuptools in their setup.py so conda build generated the egg information. So you have basically three options.   You can take the union of the conda list and pip freeze and manage packages that were installed using conda (that show in the conda list) with the conda package manager and the ones that are installed with pip (that show in pip freeze but not in conda list) with pip.</li> Install in your environment only the python, pip and distribute packages and manage everything with pip. (This is not that trivial if you're on Windows...)</li> Build your own conda packages, and manage everything with conda.</li> </ol>  I would personally recommend the third option since it's very easy to build conda packages. There is a git repository of example recipes on the continuum's github account. But it usually boils down to:   conda skeleton pypi PACKAGE  conda build PACKAGE </pre>  or just:  conda pipbuild PACKAGE </pre>  Also when you have built them once, you can upload them to  href=\"\"https://binstar.org/\"\">https://binstar.org/</ and just install from there.  Then you'll have everything managed using conda. "]
    },
    {
        "tag": "osx-mavericks",
        "patrones": ["Can't install PIL after Mac OS X 10.9","mac os PIL"],
        "respuestas": ["Following worked for me:  ln -s  /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.9.sdk/System/Library/Frameworks/Tk.framework/Versions/8.5/Headers/X11 /usr/local/include/X11 sudo pip install pil </pre>  UPDATE:  But there is more correct solution below, provided by Will.  <blockquote>   open your terminal and execute:   xcode-select --install </blockquote> "]
    },
    {
        "tag": "Error Crypto",
        "patrones": ["ImportError: No module named Crypto.Cipher"],
        "respuestas": ["I had the same problem on my Mac when installing with pip. I then removed pycrypto and installed it again with easy_install, like this:  pip uninstall pycrypto easy_install pycrypto </pre>  also as Luke commented: If you have trouble running these commands, be sure to run them as admin (sudo)   Hope this helps! "]
    },
    {
        "tag": "PIL",
        "patrones": ["Installing PIL with pip","pil"],
        "respuestas": [" Install Xcode and Xcode Command Line Tools as mentioned.</li> Use Pillow instead, as PIL is basically dead. Pillow is a maintained fork of PIL.</li> </ol>   href=\"\"https://pypi.python.org/pypi/Pillow/2.2.1\"\">https://pypi.python.org/pypi/Pillow/2.2.1</  pip install Pillow </pre>  If you have both Pythons installed and want to install this for Python3:  $ python3 -m pip install Pillow </pre> "]
    },
    {
        "tag": "osx",
        "patrones": ["how to install pip for python3 on mac os x","osx python 3","osx"],
        "respuestas": ["UPDATE: This is no longer necessary with Python3.4. It installs pip3 as part of the stock install.  I ended up posting this same question on the python mailing list, and got the following answer:  # download and install setuptools curl -O https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py python3 ez_setup.py # download and install pip curl -O https://bootstrap.pypa.io/get-pip.py python3 get-pip.py </pre>  Which solved my question perfectly. After adding the following for my own:  cd /usr/local/bin ln -s ../../../Library/Frameworks/Python.framework/Versions/3.3/bin/pip pip </pre>  So that I could run pip directly, I was able to:  # use pip to install pip install pyserial </pre>  or:  # Don't want it? pip uninstall pyserial </pre> "]
    },
    {
        "tag": "Error ubuntu",
        "patrones": ["Ubuntu running `pip install` gives error 'The following required packages can not be built: * freetype'","error ubuntu", "ubuntu error"],
        "respuestas": ["No. pip will not install system-level dependencies. This means pip will not install RPM(s) (<em>Redhat based systems</em>) or DEB(s) (<em>Debian based systems</em>).  To install system dependencies you will need to use one of the following methods depending on your system.  Ubuntu/Debian:  apt-get install libfreetype6-dev </pre>  To search for packages on Ubuntu/Debian based systems:  apt-cache search &lt;string&gt; </pre>  e.g:  apt-cache search freetype | grep dev </pre>  <hr>  Redhat/CentOS/Fedora:  yum -y install freetype-devel </pre>  To search for packages on Redhat/CentOS/Fedora based systems:  yum search &lt;string&gt; </pre>  e.g:  yum search freetype | grep devel </pre>  <hr>  Mac OS X: (<em>via  href=\"\"http://brew.sh\"\">Homebrew</</em>)  brew install freetype </pre>  To search for packages on Redhat/CentOS/Fedora based systems:  brew search &lt;string&gt; </pre>  e.g:  brew search freetype </pre> "]
    },
    {
        "tag": "Conda",
        "patrones": ["What is the difference between pip and conda?","conda pip","conda"],
        "respuestas": ["Quoting from the  href=\"\"https://www.continuum.io/blog/developer-blog/python-packages-and-environments-conda\"\" rel=\"\"nofollow\"\">Conda blog</:  <blockquote>   Having been involved in the python world for so long, we are all aware of pip, easy_install, and virtualenv, but these tools did not meet all of our specific requirements. The main problem is that they are focused around Python, neglecting non-Python library dependencies, such as HDF5, MKL, LLVM, etc., which do not have a setup.py in their source code and also do not install files into Python’s site-packages directory. </blockquote>  So Conda is a packaging tool and installer that aims to do more than what pip does; handle library dependencies <em>outside</em> of the Python packages as well as the Python packages themselves. Conda also creates a virtual environment, like virtualenv does.  As such, Conda should be compared to  href=\"\"http://www.buildout.org/en/latest/\"\" rel=\"\"nofollow\"\">Buildout</ perhaps, another tool that lets you handle both Python and non-Python installation tasks.  Because Conda introduces a new packaging format, you cannot use pip and Conda interchangeably;  pip cannot install the Conda package format. You can use the two tools side by side but they do not interoperate either. "]
    },
    {
        "tag": "pillow",
        "patrones": ["Installing Pillow/PIL on Mavericks","pillow"],
        "respuestas": ["I solved that problem the following way. Propably has something to do with todays Mavericks commandline tools update. Try adding following to the terminal before executing pip install:  export CFLAGS=-Qunused-arguments export CPPFLAGS=-Qunused-arguments </pre> "]
    },
    {
        "tag": "bcrypt",
        "patrones": ["Error installing bcrypt with pip on OS X: cant find ffi.h (libffi is installed)"],
        "respuestas": ["Without using sudo and CFLAGS and CPPFLAGS (unnecessary for pip):  $ brew install pkg-config libffi $ export PKG_CONFIG_PATH=/usr/local/Cellar/libffi/3.0.13/lib/pkgconfig/ $ pip install bcrypt </pre> "]
    },
    {
        "tag": "Error ",
        "patrones": ["DistutilsOptionError: must supply either home or prefix/exec-prefix -- not both","error"],
        "respuestas": ["Are you using OS X and Homebrew?  The Homebrew python page  href=\"\"https://github.com/Homebrew/brew/blob/master/docs/Homebrew-and-Python.md\"\" rel=\"\"nofollow\"\">https://github.com/Homebrew/brew/blob/master/docs/Homebrew-and-Python.md</ calls out a known issue with pip and a work around.  Worked for me.  <blockquote>   You can make this \"\"empty prefix\"\" the default by adding a   ~/.pydistutils.cfg file with the following contents:  [install] prefix= </pre> </blockquote>  Edit: Do not use this Homebrew recommended option, it will break normal pip operations. "]
    },
    {
        "tag": "lxml",
        "patrones": ["lxml installation error ubuntu 14.04 (internal compiler error)"],
        "respuestas": ["Possible solution (if you have no ability to increase memory on that machine) is to add swap file.  sudo dd if=/dev/zero of=/swapfile bs=1024 count=524288 sudo chmod 600 /swapfile sudo mkswap /swapfile sudo swapon /swapfile </pre>  from  href=\"\"https://github.com/pydata/pandas/issues/1880#issuecomment-9920484\"\">https://github.com/pydata/pandas/issues/1880#issuecomment-9920484</  This worked for me on smallest digital ocean machine "]
    },
    {
        "tag": "whl",
        "patrones": ["How do I install a Python package with a .whl file?"],
        "respuestas": ["<p>I just used the following which was quite simple. First open a console then cd to where you've downloaded your file like some-package.whl and use  pip install some-package.whl </pre>  <p>Note: if pip.exe is not recognized, you may find it in the \"\"Scripts\"\" directory from where python has been installed. If pip is not installed, this page can help:  href=\"\"http://stackoverflow.com/questions/4750806/how-to-install-pip-on-windows\"\">How do I install pip on Windows?</  <p><em>Note: for clarification</em><br> If you copy the *.whl file to your local drive (ex. C:\\some-dir\\some-file.whl) use the following command line parameters --    pip install C:/some-dir/some-file.whl </pre> "]
    },
    {
        "tag": "installation",
        "patrones": ["pip installation /usr/local/opt/python/bin/python2.7: bad interpreter: No such file or directory"],
        "respuestas": ["<p>I had used home-brew to install 2.7 on OS X 10.10 and the new install was missing the sym links. I ran  brew link --overwrite python </pre>  <p>as mentioned in  href=\"\"http://stackoverflow.com/questions/13354207/how-to-symlink-python-in-homebrew/13354417#13354417\"\">How to symlink python in Homebrew?</ and it solved the problem. "]
    }
   
]
}